{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "https://github.com/FrederikSchorr/sign-language<br>\n", "Utilites to launch webcam, capture/record video, show rectangles & text on screen.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["import the necessary packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from timer import Timer\n", "from frame import image_crop, images_crop, frames_show\n", "from opticalflow import OpticalFlow, frames2flows, flow2colorimage, flows2colorimages, unittest_fromfile"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def video_start(device = 0, tuResolution =(320, 240), nFramePerSecond = 30):\n", "\t\"\"\" Returns videocapture object/stream"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tParameters:\n", "\t\tdevice: 0 for the primary webcam, 1 for attached webcam\n", "\t\"\"\"\n", "\t\n", "\t# try to open webcam device\n", "\toStream = cv2.VideoCapture(device) \n", "\tif not oStream.isOpened():\n", "\t\t# try again with inbuilt camera\n", "\t\tprint(\"Try to initialize inbuilt camera ...\")\n", "\t\tdevice = 0\n", "\t\toStream = cv2.VideoCapture(device)\n", "\t\tif not oStream.isOpened(): raise ValueError(\"Could not open webcam\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# set camera resolution\n", "\tnWidth, nHeight = tuResolution\n", "\toStream.set(3, nWidth)\n", "\toStream.set(4, nHeight)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# try to set camera frame rate\n", "\toStream.set(cv2.CAP_PROP_FPS, nFramePerSecond)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tprint(\"Initialized video device %d, with resolution %s and target frame rate %d\" % \\\n", "\t\t(device, str(tuResolution), nFramePerSecond))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn oStream"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rectangle_text(arImage, sColor, sUpper, sLower = None, tuRectangle = (224, 224)):\n", "\t\"\"\" Returns new image (not altering arImage)\n", "\t\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tnHeigth, nWidth, _ = arImage.shape\n", "\tnRectHeigth, nRectWidth = tuRectangle\n", "\tx1 = int((nWidth - nRectWidth) / 2)\n", "\ty1 = int((nHeigth - nRectHeigth) / 2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tif sColor == \"green\": bgr = (84, 175, 25)\n", "\telif sColor == \"orange\": bgr = (60, 125, 235)\n", "\telse: #sColor == \"red\": \n", "\t\tbgr = (27, 13, 252)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tarImageNew = np.copy(arImage)\n", "\tcv2.rectangle(arImageNew, (x1, y1), (nWidth-x1, nHeigth-y1), bgr, 3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# display a text to the frame \n", "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n", "\tfFontSize = 0.5\n", "\ttextSize = cv2.getTextSize(sUpper, font, 1.0, 2)[0]\n", "\tcv2.putText(arImageNew, sUpper, (x1 + 7, y1 + textSize[1] + 7), font, fFontSize, bgr, 2)\t"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# 2nd text\n", "\tif (sLower != None):\n", "\t\ttextSize = cv2.getTextSize(sLower, font, 1.0, 2)[0]\n", "\t\tcv2.putText(arImageNew, sLower, (x1 + 7, nHeigth - y1 - 7), font, fFontSize, bgr, 2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn arImageNew"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def video_show(oStream, sColor, sUpper, sLower = None, tuRectangle = (224, 224), nCountdown = 0): \n", "\t\n", "\tif nCountdown > 0: \n", "\t\tfTimeTarget = time.time() + nCountdown\n", "\t\n", "\t# loop over frames from the video file stream\n", "\ts = sUpper\n", "\twhile True:\n", "\t\t# grab the frame from the threaded video file stream\n", "\t\t(bGrabbed, arFrame) = oStream.read()\n", "\t\tif bGrabbed == False: continue"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tif nCountdown > 0:\n", "\t\t\tfCountdown = fTimeTarget - time.time()\n", "\t\t\ts = sUpper + str(int(fCountdown)+1) + \" sec\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# paint rectangle & text, show the (mirrored) frame\n", "\t\tarFrame = rectangle_text(cv2.flip(arFrame, 1), sColor, s, sLower, tuRectangle)\n", "\t\tcv2.imshow(\"Video\", arFrame)\n", "\t\n", "\t\t# stop after countdown\n", "\t\tif nCountdown > 0 and fCountdown <= 0.0:\n", "\t\t\tkey = -1\n", "\t\t\tbreak"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# Press 'q' to exit live loop\n", "\t\tkey = cv2.waitKey(1) & 0xFF\n", "\t\tif key != 0xFF: break\n", "\treturn key"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def video_capture(oStream, sColor, sText, tuRectangle = (224, 224), nTimeDuration = 3, bOpticalFlow = False) -> \\\n", "\t(float, np.array, np.array):\n", "\t\n", "\tif bOpticalFlow:\n", "\t\toOpticalFlow = OpticalFlow(bThirdChannel = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tliFrames = []\n", "\tliFlows = []\n", "\tfTimeStart = time.time()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# loop over frames from the video file stream\n", "\twhile True:\n", "\t\t# grab the frame from the threaded video file stream\n", "\t\t(bGrabbed, arFrame) = oStream.read()\n", "\t\tarFrame = cv2.flip(arFrame, 1)\n", "\t\tliFrames.append(arFrame)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tfTimeElapsed = time.time() - fTimeStart\n", "\t\ts = sText + str(int(fTimeElapsed)+1) + \" sec\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# paint rectangle & text, show the frame\n", "\t\tarFrameText = rectangle_text(arFrame, sColor, s, \"\", tuRectangle)\n", "\t\tcv2.imshow(\"Video\", arFrameText)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# display optical flow\n", "\t\tif bOpticalFlow:\n", "\t\t\tarFlow = oOpticalFlow.next(image_crop(arFrame, *tuRectangle))\n", "\t\t\tliFlows.append(arFlow)\n", "\t\t\tcv2.imshow(\"Optical flow\", flow2colorimage(arFlow))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# stop after nTimeDuration sec\n", "\t\tif fTimeElapsed >= nTimeDuration: break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# Press 'q' for early exit\n", "\t\tkey = cv2.waitKey(1) & 0xFF\n", "\t\tif key == ord('q'): break\n", "\t\tcv2.waitKey(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn fTimeElapsed, np.array(liFrames), np.array(liFlows)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def frame_show(oStream, sColor:str, sText:str, tuRectangle = (224, 224)):\n", "\t\"\"\" Read frame from webcam and display it with box+text \"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t(bGrabbed, oFrame) = oStream.read()\n", "\toFrame = rectangle_text(cv2.flip(oFrame, 1), sColor, sText, \"\", tuRectangle)\n", "\tcv2.imshow(\"Video\", oFrame)\n", "\tcv2.waitKey(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def unittest_videocapture():\n", "\t# open a pointer to the video stream\n", "\toStream = video_start(device = 1, tuResolution = (320, 240), nFramePerSecond = 15)\n", "\t#liFrames = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# loop over action states\n", "\tsResults = \"\"\n", "\twhile True:\n", "\t\t# show live video and wait for key stroke\n", "\t\tkey = video_show(oStream, \"green\", \"Press <blank> to start\", sResults)\n", "\t\t\n", "\t\t# start!\n", "\t\tif key == ord(' '):\n", "\t\t\t# countdown n sec\n", "\t\t\tvideo_show(oStream, sColor = \"orange\", sUpper = \"Recording starts in \", sLower = None, \n", "\t\t\t\ttuRectangle = (224, 224), nCountdown = 3)\n", "\t\t\t\n", "\t\t\t# record video for n sec\n", "\t\t\tfElapsed, liFrames, _ = video_capture(oStream, \"red\", \"Recording \", nTimeDuration=5, bOpticalFlow=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# show orange wait box\n", "\t\t\tframe_show(oStream, \"orange\", \"Translating sign ...\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# run NN to translate video to label\n", "\t\t\ttime.sleep(3)\n", "\t\t\tsResults = \"Video duration {:.1f} sec, {} frames recorded, {:.1f} fps\". \\\n", "\t\t\t\tformat(fElapsed, len(liFrames), len(liFrames)/fElapsed)\n", "\t\t\tprint(sResults)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# ready for next video\t"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\telif key == ord(\"+\"):\n", "\t\t\tfFPS *= 2.\n", "\t\t\tprint(\"Frame per second increased from %.1f to %.1f\" % (oStream.get(cv2.CAP_PROP_FPS),fFPS))\n", "\t\t\toStream.set(cv2.CAP_PROP_FPS, fFPS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\telif key == ord(\"-\"):\n", "\t\t\tfFPS /= 2.\n", "\t\t\tprint(\"Frame per second decreased from %.1f to %.1f\" % (oStream.get(cv2.CAP_PROP_FPS), fFPS))\n", "\t\t\toStream.set(cv2.CAP_PROP_FPS, fFPS)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# quit\n", "\t\telif key == ord('q'):\n", "\t\t\tbreak"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\tcv2.waitKey(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# do a bit of cleanup\n", "\toStream.release()\n", "\tcv2.destroyAllWindows()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def unittest_opticalflow_fromcamera():\n", "    timer = Timer()\n\n", "    # start video capture from webcam\n", "    oStream = video_start(1, (320, 240), 15)\n\n", "    # loop over action states\n", "    while True:\n", "        # show live video and wait for key stroke\n", "        key = video_show(oStream, \"green\", \"Press <blank> to start\", \"\")\n", "        \n", "        # start!\n", "        if key == ord(' '):\n", "            # countdown n sec\n", "            video_show(oStream, \"orange\", \"Recording starts in \", sLower = None, \\\n", "\t\t\t\ttuRectangle = (224, 224), nCountdown = 3)\n", "            \n", "            # record video for n sec\n", "            fElapsed, arFrames, _ = video_capture(oStream, \"red\", \"Recording \", \\\n", "\t\t\t\ttuRectangle = (224, 224), nTimeDuration = 5, bOpticalFlow = False)\n", "            print(\"\\nCaptured video: %.1f sec, %s, %.1f fps\" % \\\n", "                (fElapsed, str(arFrames.shape), len(arFrames)/fElapsed))\n\n", "            # show orange wait box\n", "            frame_show(oStream, \"orange\", \"Calculating optical flow ...\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# calculate and show optical flow\n", "            arFrames = images_crop(arFrames, 224, 224)\n", "            timer.start()\n", "            arFlows = frames2flows(arFrames, bThirdChannel=True)\n", "            print(\"Optical flow per frame: %.3f\" % (timer.stop() / len(arFrames)))\n", "            frames_show(flows2colorimages(arFlows), int(5 * 1000 / len(arFrames)))    \n", "        elif key == ord('f'):\n", "            unittest_fromfile()\n\n", "        # quit\n", "        elif key == ord('q'):\n", "            break\n\n", "    # do a bit of cleanup\n", "    oStream.release()\n", "    cv2.destroyAllWindows()\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    unittest_videocapture()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}