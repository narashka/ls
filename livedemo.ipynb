{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "https://github.com/FrederikSchorr/sign-language<br>\n", "This module <br>\n", "* launches the webcam, <br>\n", "* waits for the start signal from user,<br>\n", "* captures 5 seconds of video,<br>\n", "* extracts frames from the video<br>\n", "* calculates and displays the optical flow,<br>\n", "* and uses the neural network to predict the sign language gesture.<br>\n", "* Then start again.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["import the necessary packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import os\n", "import glob\n", "import sys\n", "import random"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from timer import Timer\n", "from frame import video2frames, images_normalize, frames_downsample, images_crop\n", "from frame import images_resize_aspectratio, frames_show, frames2files, files2frames, video_length\n", "from videocapture import video_start, frame_show, video_show, video_capture\n", "from opticalflow import frames2flows, flows2colorimages, flows2file, flows_add_third_channel\n", "from datagenerator import VideoClasses\n", "from model_i3d import I3D_load\n", "from predict import probability2label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def livedemo():\n", "\t\n", "\t# dataset\n", "\tdiVideoSet = {\"sName\" : \"chalearn\",\n", "\t\t\"nClasses\" : 20,   # number of classes\n", "\t\t\"nFramesNorm\" : 40,    # number of frames per video\n", "\t\t\"nMinDim\" : 224,   # smaller dimension of saved video-frames\n", "\t\t\"tuShape\" : (224, 224), # height, width\n", "\t\t\"nFpsAvg\" : 10,\n", "\t\t\"nFramesAvg\" : 50, \n", "\t\t\"fDurationAvg\" : 5.0} # seconds "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# files\n", "\tsClassFile       = \"data-set/%s/%03d/class.csv\"%(diVideoSet[\"sName\"], diVideoSet[\"nClasses\"])\n", "\tsVideoDir        = \"data-set/%s/%03d\"%(diVideoSet[\"sName\"], diVideoSet[\"nClasses\"])\n", "\t\n", "\tprint(\"\\nStarting gesture recognition live demo ... \")\n", "\tprint(os.getcwd())\n", "\tprint(diVideoSet)\n", "\t\n", "\t# load label description\n", "\toClasses = VideoClasses(sClassFile)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\tsModelFile = \"model/20190511-2107-chalearn249-oflow-i3d-entire-best.h5\"\n", "\th, w = 224, 224\n", "\tkeI3D = I3D_load(sModelFile, diVideoSet[\"nFramesNorm\"], (h, w, 2), oClasses.nClasses)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# open a pointer to the webcam video stream\n", "\toStream = video_start(device = 1, tuResolution = (224,224), nFramePerSecond = diVideoSet[\"nFpsAvg\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t#liVideosDebug = glob.glob(sVideoDir + \"/train/*/*.*\")\n", "\tnCount = 0\n", "\tsResults = \"\"\n", "\ttimer = Timer()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# loop over action states\n", "\twhile True:\n", "\t\t# show live video and wait for key stroke\n", "\t\tkey = video_show(oStream, \"green\", \"Press <blank> to start\", sResults, tuRectangle = (h, w))\n", "\t\t\n", "\t\t# start!\n", "\t\tif key == ord(' '):\n", "\t\t\t# countdown n sec\n", "\t\t\tvideo_show(oStream, \"orange\", \"Recording starts in \", tuRectangle = (h, w), nCountdown = 3)\n", "\t\t\t\n", "\t\t\t# record video for n sec\n", "\t\t\tfElapsed, arFrames, _ = video_capture(oStream, \"red\", \"Recording \", \\\n", "\t\t\t\ttuRectangle = (h, w), nTimeDuration = int(diVideoSet[\"fDurationAvg\"]), bOpticalFlow = False)\n", "\t\t\tprint(\"\\nCaptured video: %.1f sec, %s, %.1f fps\" % \\\n", "\t\t\t\t(fElapsed, str(arFrames.shape), len(arFrames)/fElapsed))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# show orange wait box\n", "\t\t\tframe_show(oStream, \"orange\", \"Translating sign ...\", tuRectangle = (h, w))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# crop and downsample frames\n", "\t\t\tarFrames = images_crop(arFrames, h, w)\n", "\t\t\tarFrames = frames_downsample(arFrames, diVideoSet[\"nFramesNorm\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# Translate frames to flows - these are already scaled between [-1.0, 1.0]\n", "\t\t\tprint(\"Calculate optical flow on %d frames ...\" % len(arFrames))\n", "\t\t\ttimer.start()\n", "\t\t\tarFlows = frames2flows(arFrames, bThirdChannel = False, bShow = True)\n", "\t\t\tprint(\"Optical flow per frame: %.3f\" % (timer.stop() / len(arFrames)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\t# predict video from flows\t\t\t\n", "\t\t\tprint(\"Predict video with %s ...\" % (keI3D.name))\n", "\t\t\tarX = np.expand_dims(arFlows, axis=0)\n", "\t\t\tarProbas = keI3D.predict(arX, verbose = 1)[0]\n", "\t\t\tnLabel, sLabel, fProba = probability2label(arProbas, oClasses, nTop = 3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t\tsResults = \"Sign: %s (%.0f%%)\" % (sLabel, fProba*100.)\n", "\t\t\tprint(sResults)\n", "\t\t\tnCount += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t\t# quit\n", "\t\telif key == ord('q'):\n", "\t\t\tbreak"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\t# do a bit of cleanup\n", "\toStream.release()\n", "\tcv2.destroyAllWindows()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\treturn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "\tlivedemo()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}